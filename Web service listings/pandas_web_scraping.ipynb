{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pandas web scraping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQf4yIMfnk32"
      },
      "source": [
        "# Sample Source Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3Q8HPBI4k7c"
      },
      "source": [
        "## Pandas HTML + BeautifulSoup\n",
        "\n",
        "+600 web requests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-omHl_ud753"
      },
      "source": [
        "!pip install requests-random-user-agent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7LjkVSMfmej"
      },
      "source": [
        "import multiprocessing\n",
        "multiprocessing.cpu_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygC_TkLgs6cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e72dfbb4-e922-4792-a63d-847dce40e12c"
      },
      "source": [
        "\n",
        "import requests\n",
        "import requests_random_user_agent\n",
        "#s = requests.Session()\n",
        "#print(s.headers['User-Agent'])\n",
        "\n",
        "# Without a session\n",
        "resp = requests.get('https://httpbin.org/user-agent')\n",
        "print(resp.json()['user-agent'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.67 Safari/537.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEktJZW9ojM4"
      },
      "source": [
        "import concurrent.futures\n",
        "import requests\n",
        "import requests_random_user_agent\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def download_sourceCode_url(url):\n",
        "\n",
        "  rq = requests.get(url)\n",
        "  \n",
        "  if rq.status_code == 404 or rq.status_code == 403: ## Handle more error codes...\n",
        "    exit\n",
        "\n",
        "  main_data = rq.text\n",
        "\n",
        "  # dataset from table\n",
        "  df_tempSourceCode = pd.read_html(main_data, index_col=0)[0]\n",
        "\n",
        "  main_soup = BeautifulSoup(main_data, 'html.parser')\n",
        "  main_names = main_soup.find_all('tr')[1:245]\n",
        "\n",
        "  list_urlSourceCode = []\n",
        "\n",
        "  # Head url for meta_url\n",
        "  head_Url= 'https://www.programmableweb.com'\n",
        "\n",
        "  for row in main_names:\n",
        "      text = row.find_all('td')[0]\n",
        "      list_urlSourceCode.append( (head_Url + str(text).partition('<a href=\"')[2].partition('\">')[0]))\n",
        "\n",
        "  df_tempSourceCode['Meta_Url'] = list_urlSourceCode\n",
        "\n",
        "  return df_tempSourceCode\n",
        "\n",
        "\n",
        "def download_sourceCode_bulk_url(story_urls):\n",
        "  df_temp = pd.DataFrame()\n",
        "\n",
        "  # Partimos las url\n",
        "  lst_splited  = np.array_split(story_urls, 100) # max workers\n",
        "\n",
        "  tasks = []\n",
        "\n",
        "  for split in range(len(lst_splited)):\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers = len(lst_splited)) as executor:\n",
        "      for url in lst_splited[split]:    \n",
        "        tasks.append(executor.submit(download_sourceCode_url, url))\n",
        "\n",
        "  for result in tasks:\n",
        "    df_temp = df_temp.append(result.result())\n",
        "\n",
        "  return df_temp\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwzcvGg9XkxZ"
      },
      "source": [
        "\n",
        "sourceCode_urls=[]\n",
        "for i in range(200): ## web pages?.. 615\n",
        "    main_url = 'https://www.programmableweb.com/category/all/sample-source-code?page=' + str(i) ## parametrizar + comprobar que hay datos\n",
        "    sourceCode_urls.append(main_url)\n",
        "\n",
        "df_sourceCode = pd.DataFrame()\n",
        "df_sourceCode = download_sourceCode_bulk_url(sourceCode_urls)\n",
        "df_sourceCode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-SOQXFy2Nhn"
      },
      "source": [
        "df_sourceCode[df_sourceCode.duplicated(keep=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dmljlR5Eac4"
      },
      "source": [
        "## Meta URL Processing\n",
        "\n",
        "+15k web requests -> split?\n",
        "\n",
        "TODO> threading\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLimtCPvq9RL"
      },
      "source": [
        "# Creates new columns\n",
        "df_sourceCode['Source Code'] = \"\"\n",
        "df_sourceCode['Repository'] = \"\"\n",
        "df_sourceCode['Languages'] = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tbW6UpLhTnv"
      },
      "source": [
        "for i in range(len(df_sourceCode)):\n",
        "\n",
        "    meta_url = df_sourceCode['Meta_Url'][i]\n",
        "    rq = requests.get(meta_url)\n",
        "\n",
        "    if rq.status_code == 404 or rq.status_code == 403: ## Handle more error codes...\n",
        "      continue\n",
        "\n",
        "    meta_data = rq.text\n",
        "    meta_soup = BeautifulSoup(meta_data, 'html.parser')\n",
        "\n",
        "    # Update Description from the meta url\n",
        "    meta_description = str(meta_soup.find('div', class_='tabs-header_description')).partition('\">')[2].partition('</')[0]\n",
        "    df_sourceCode['Description'][i] = meta_description \n",
        "\n",
        "    meta_specs = meta_soup.find('div', class_='section specs')\n",
        "\n",
        "    for lab in meta_specs.select(\"label\"):   \n",
        "\n",
        "      # Search for Repo\n",
        "      if (lab.text.lower().find(\"repository\") > -1):\n",
        "          #print(lab.text + \": \" + lab.find_next_sibling().text)\n",
        "          df_sourceCode['Repository'][i] =   lab.find_next_sibling().text\n",
        "\n",
        "       # Search for Source Code\n",
        "      if (lab.text.lower().find(\"link to source code\") > -1):\n",
        "          #print(lab.text + \": \" + lab.find_next_sibling().text)\n",
        "          df_sourceCode['Source Code'][i] =   lab.find_next_sibling().text\n",
        "\n",
        "      # Search for Categories and remplace them\n",
        "      if (lab.text.lower().find(\"categories\") > -1):\n",
        "         #print(lab.text + \": \" + lab.find_next_sibling().text)\n",
        "          df_sourceCode['Category'][i] =   lab.find_next_sibling().text\n",
        "\n",
        "      # Search for Languages\n",
        "      if (lab.text.lower().find(\"languages\") > -1):\n",
        "          #print(lab.text + \": \" + lab.find_next_sibling().text)\n",
        "          df_sourceCode['Languages'][i] =   lab.find_next_sibling().text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-6HqdxVTch_"
      },
      "source": [
        "# Meta_Url could be used to check for updates on the source website. That uses only +600 web requests instead of +15k\n",
        "# save a copy of the original dataframe to check for updates based on the meta url or other fields\n",
        "df_sourceCode.reset_index(inplace=True)\n",
        "df_export_sourceCode = df_sourceCode.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm3aE3MPjDxa"
      },
      "source": [
        "# Drop the column for the data analysis ( ? ? )\n",
        "df_export_sourceCode.drop('Meta_Url', inplace=True, axis=1)\n",
        "df_export_sourceCode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3S8CUZhV4W9"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6qGQJEcUmD9"
      },
      "source": [
        "from datetime import datetime\n",
        "datetime = datetime.now()\n",
        "\n",
        "## Export the data for analysis \n",
        "# To CSV (index True 0,1,2...)\n",
        "df_export_sourceCode.to_csv(r'/content/DataFrame/sample_source_code_' + datetime.now().strftime('%d_%m_%Y') + '.csv', index = True, header = True)\n",
        "\n",
        "# To JSON (columns format index True 0,1,2...)\n",
        "df_export_sourceCode.to_json(r'/content/DataFrame/sample_source_code_' + datetime.now().strftime('%d_%m_%Y') + '.json')\n",
        "\n",
        "\n",
        "## Export the original + Meta_Url\n",
        "\n",
        "# To CSV (index True 0,1,2...)\n",
        "df_sourceCode.to_csv(r'/content/DataFrame/original_sample_source_code_' + datetime.now().strftime('%d_%m_%Y') + '.csv', index = True, header = True)\n",
        "\n",
        "# To JSON (columns format index True 0,1,2...)\n",
        "df_sourceCode.to_json(r'/content/DataFrame/original_sample_source_code_' + datetime.now().strftime('%d_%m_%Y') + '.json')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}